server:
  privateport: 3083
  publicport: 8083
  https:
    cert:
    key:
  edition: local-ce:dev
  usage:
    enabled: true
    tlsenabled: true
    host: usage.instill.tech
    port: 443
  debug: true
  itmode:
    enabled: false
  maxdatasize: 20 # MB in unit
  workflow:
    maxworkflowtimeout: 7200 # in seconds
    maxworkflowretry: 3
    maxactivityretry: 1
  inferencebackend: ray
database:
  username: postgres
  password: password
  host: pg-sql
  port: 5432
  name: model
  version: 2
  timezone: Etc/UTC
  pool:
    idleconnections: 5
    maxconnections: 30
    connlifetime: 30m # In minutes, e.g., '60m'
tritonserver:
  grpcuri: triton-server:8001
  modelstore: /model-repository
rayserver:
  grpcuri: ray-server:9000
  modelstore: /model-repository
mgmtbackend:
  host: mgmt-backend
  privateport: 3084
  https:
    cert:
    key:
cache:
  redis:
    redisoptions:
      addr: redis:6379
  model: false
maxbatchsizelimitation:
  unspecified: 2
  classification: 16
  detection: 8
  keypoint: 8
  ocr: 2
  instancesegmentation: 8
  semanticsegmentation: 8
  textgeneration: 1
temporal:
  hostport: temporal:7233
  namespace: model-backend
  ca:
  cert:
  key:
  servername:
controller:
  host: controller-model
  privateport: 3086
  https:
    cert:
    key:
initmodel:
  enabled: false
  path: https://raw.githubusercontent.com/instill-ai/model/main/model-hub/model_hub_cpu.json
log:
  external: false
  otelcollector:
    host: otel-collector
    port: 8095
